{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from os import path\n",
    "\n",
    "from unicodedata import normalize\n",
    "\n",
    "DIR = '../data'\n",
    "\n",
    "cities_data = None\n",
    "with open('../cidades/cities.json') as f:\n",
    "    cities_data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalized(text):\n",
    "    try:\n",
    "        return normalize('NFKD', text).encode('ASCII','ignore').decode('ASCII')\n",
    "    except:\n",
    "        pass\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def document_iterator(DIR):\n",
    "    for index, file in enumerate(glob(path.join(DIR, '*.txt'))):\n",
    "        yield (open(file, 'r', encoding='cp1252').read(), file)\n",
    "        if index >= 1000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_codigo(filename):\n",
    "    return re.sub(r\"\\_.\\.txt\",\"\",filename.replace(DIR,\"\")).replace('\\\\', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_process_num(content):\n",
    "    process_num_matches = re.findall(r\"proc(?:esso|.)(?:[^\\d]{0,15})((?:\\d|-|\\.|\\s\\/\\s?)*)\", content, re.IGNORECASE)\n",
    "    for match in process_num_matches:\n",
    "        if match:\n",
    "            return match\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _find_state(text):\n",
    "    for state in cities_data:\n",
    "        if state in text:\n",
    "            return state\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def _find_city(state, text):\n",
    "    for city in cities_data[state]:\n",
    "        if city in text:\n",
    "            return city\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_estado_e_comarca(file):\n",
    "    uf, comarca = None, None\n",
    "    states = re.findall(r'estado [\\w\\t\\r\\n]*\\s*[^\\n\\r]*', file, re.IGNORECASE)\n",
    "    cities = re.findall(r'comarca\\s?\\:?[\\w\\t\\r\\n\\:]*\\s*[^\\n\\r]*', file, re.IGNORECASE)\n",
    "    if len(states):\n",
    "        text = ''.join(states[0])\n",
    "        uf = _find_state(text.lower().strip())\n",
    "        if len(cities) and uf:\n",
    "            text = ''.join(cities[0])\n",
    "            comarca = _find_city(uf.lower().strip(), text.lower().strip())\n",
    "\n",
    "    return uf, comarca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compile_multiple(regexes):\n",
    "    programs = []\n",
    "    for regex in regexes:\n",
    "        programs.append(re.compile(regex, re.IGNORECASE))\n",
    "    return programs\n",
    "\n",
    "def varas_identify(text):\n",
    "    p = re.compile('(^|\\W)vara\\W', re.IGNORECASE)\n",
    "    lines = []\n",
    "    for line in text.splitlines():\n",
    "        if p.search(line) is not None:\n",
    "            lines.append(normalized(line.strip()))\n",
    "    return lines\n",
    "\n",
    "def varas_filter(lines):\n",
    "    regexes = ['\\d+[ª,a]?.*vara\\W', '(^|\\W)Vara d[e,o,a]', '(^|\\W)Vara:', '(^|\\W)Vara civel', '(^|\\W)Vara comercial', '(^|\\W)Vara regional', '\\w+eira vara', 'segunda vara', 'quarta vara', 'quinta vara', 'sexta vara', 'setima vara', 'oitava vara', 'decima vara', 'nona vara', '\\w+esima vara', 'vara unica', 'vara judicial']\n",
    "\n",
    "    programs = compile_multiple(regexes)\n",
    "\n",
    "    regex_filtered = []\n",
    "    for text in lines:\n",
    "        for p in programs:\n",
    "            if p.search(text) is not None:\n",
    "                regex_filtered.append(text)\n",
    "                break\n",
    "    return regex_filtered\n",
    "\n",
    "def varas_first(lines):\n",
    "    if len(lines) > 0:\n",
    "        return lines[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def varas_from_matching(line):\n",
    "    startregexes = ['primeira vara.*', 'segunda vara.*', 'terceira vara.*', 'quarta vara.*', 'quinta vara.*', 'sexta vara.*', 'setima vara.*', 'oitava vara.*', 'decima vara.*', 'nona vara.*', '\\w+esima vara.*', '\\d+[ª,a]?(.{2}|\\s)vara\\W.*', 'vara unica', 'vara judicial', '(^|\\W)Vara civel .*', '(^|\\W)Vara comercial', '(^|\\W)Vara regional .*', '(^|\\W)Vara .*']\n",
    "\n",
    "    programs = compile_multiple(startregexes)\n",
    "    if line is not None:\n",
    "        for p in programs:\n",
    "            if p.search(line) is not None:\n",
    "                return p.search(line).group(0).strip()\n",
    "    \n",
    "    return line\n",
    "\n",
    "def varas_final_value(line):\n",
    "    p = re.compile('(\\s\\s+|,|-)')\n",
    "\n",
    "    if line is not None:\n",
    "        return p.split(line)[0].strip()\n",
    "    return line\n",
    "\n",
    "def get_vara(text):\n",
    "    lines = varas_identify(text)\n",
    "    lines = varas_filter(lines)\n",
    "    line = varas_first(lines)\n",
    "    vara = varas_from_matching(line)\n",
    "    vara = varas_final_value(vara)\n",
    "    return vara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_blank_lines(lines):\n",
    "    cleaned_lines = []\n",
    "    for line in lines:\n",
    "        copy = line\n",
    "        re.sub(\"(\\s)+\", \"\", copy)\n",
    "        if len(copy) > 0:\n",
    "            cleaned_lines.append(line)\n",
    "    return cleaned_lines\n",
    "\n",
    "def starts_with_lower(string):\n",
    "    if string[0].lower() == string[0]:\n",
    "        return True\n",
    "    \n",
    "def check_name(string):\n",
    "    bad_words = ['processo', 'sa', 'ltda', 'acao', 'vara', 'juiz', 'autos', 'contratuais', \n",
    "             'contratos', 'vistos', 'rua',\n",
    "            'a', 'ante', 'apos', 'ate', 'com', 'contra', 'em', 'entre', \n",
    "            'para', 'per', 'por', 'perante', 'sem', 'sob', 'sobre', 'tras']\n",
    "\n",
    "    words = re.split(\"\\W\",string)\n",
    "    words = [word for word in words if word != \"\"] \n",
    "    if len(words) < 2 or len(words) > 6: #supondo que o nome completo de uma pessoa deve ter mais de uma palavra\n",
    "        return False\n",
    "    if starts_with_lower(words[0]): #supondo que a primeira letra de todas mesmo do nome TEM que ser maiuscula\n",
    "        return False\n",
    "    last_lower = False\n",
    "    for word in words:\n",
    "        if word.lower() in bad_words:\n",
    "            return False\n",
    "        if len(word) < 2:\n",
    "            return False\n",
    "        if len(word) < 3: #eh razoavel supor que um nome deve ter mais que 2 caracteres\n",
    "            continue\n",
    "        first_letter_is_lower = starts_with_lower(word)\n",
    "        if first_letter_is_lower and last_lower: #primeira letra minuscula, provavelmente nao eh um nome\n",
    "            return False\n",
    "        last_lower = first_letter_is_lower\n",
    "    if string.upper() == string: #supondo que se eh tudo maiusculo e nao caiu nos outros casos\n",
    "        return True\n",
    "    return True\n",
    "\n",
    "def check_possible_names(possible_names):\n",
    "    probable = None\n",
    "    for possible_name in possible_names:\n",
    "        if not probable:\n",
    "            if check_name(possible_name):\n",
    "                probable = possible_name\n",
    "                break\n",
    "            sentences = re.split('(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', possible_name)\n",
    "            for sentence in sentences:\n",
    "                if check_name(sentence):\n",
    "                    probable = sentence\n",
    "                    break\n",
    "    return probable\n",
    "\n",
    "def find_name(line):\n",
    "    probable = None\n",
    "    normalized_s = normalized(line)\n",
    "    possible_names = re.findall('[a-zA-Z\\s]+', normalized_s)\n",
    "    probable = check_possible_names(possible_names)\n",
    "    if not probable:\n",
    "        possible_names = re.findall('[A-Z\\s]+', normalized_s)\n",
    "        probable = check_possible_names(possible_names)\n",
    "    return probable\n",
    "\n",
    "def final_name(string):\n",
    "    return string.strip().upper()\n",
    "\n",
    "def get_name_from_signature(line):\n",
    "    name = None\n",
    "    #CASO Este documento foi assinado digitalmente por [nome do juiz]\n",
    "    assinatura_re = re.findall('Este documento foi assinado digitalmente por', line)\n",
    "    if assinatura_re:\n",
    "        rest = line.replace('Este documento foi assinado digitalmente por ', '')\n",
    "        has_name = find_name(rest)\n",
    "        if has_name:\n",
    "            name = final_name(has_name)\n",
    "    return name\n",
    "\n",
    "# Pattern 1: [nome do juiz] + \"Juiz de Direito\" na mesma linha\n",
    "def find_judge_string(name, text): \n",
    "    found = re.findall('juiz.*de.*direito.*', text.lower())\n",
    "    if found:\n",
    "        return final_name(name)\n",
    "    found = re.findall('ajuiz', text.lower())\n",
    "    if found:\n",
    "        return final_name(name)\n",
    "    \n",
    "def get_line_name(i,line, lines):\n",
    "    qt_lines = len(lines)\n",
    "    name = get_name_from_signature(line)\n",
    "    if name:\n",
    "        return name\n",
    "    has_name = find_name(line)\n",
    "    if has_name:\n",
    "        name = find_judge_string(has_name, line)\n",
    "        if name:\n",
    "            return name\n",
    "        if i+1 != qt_lines:\n",
    "            name = find_judge_string(has_name, lines[i+1])\n",
    "        if name:\n",
    "            return name\n",
    "        if i != 0:\n",
    "            name = find_judge_string(has_name, lines[i-1])\n",
    "    return name\n",
    "\n",
    "def get_name(lines):\n",
    "    name = None\n",
    "    qt_lines = len(lines)\n",
    "    for i, line in enumerate(lines):\n",
    "        if name:\n",
    "            break\n",
    "        name = get_line_name(i,line,qt_lines)\n",
    "    return name\n",
    "\n",
    "def not_judge(text):\n",
    "    found = re.findall('art.*40.*Lei.*9\\.099/95', text)\n",
    "    if found:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_juiz(text):\n",
    "    name = None\n",
    "    if not_judge(text):\n",
    "        return 'LEIGO'\n",
    "        \n",
    "    lines = text.splitlines()\n",
    "    lines = clean_blank_lines(lines)\n",
    "    for i, line in enumerate(lines):\n",
    "        if name:\n",
    "            break\n",
    "        name = get_line_name(i, line, lines)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_author(content):\n",
    "    content = normalized(content)\n",
    "    author_matches = re.findall(r\"(?:(?:a|A)utora?|AUTORA?|(?:R|r)equerente|REQUERENTE|(?:(?:P|p)romovente|PROMOVENTE)\\(?(?:S|s)?\\)?|(?:D|d)emandante|DEMANDANTE)(?:[^A-Z])*([A-Z][^\\n]*)|(?:(?:V|v)istos?|VISTOS?)(?:[^A-Z]*)([A-Z\\s][^a-z]*)\", content)\n",
    "    for match in author_matches:\n",
    "        for author in match:\n",
    "            if author:\n",
    "                author = re.sub('[^\\w\\s]','',author).lower()\n",
    "                if len(author) > 4 and re.search('(\\s\\s+|[0-9])', author) is None:\n",
    "                    return author.strip()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lawyer(content):\n",
    "    lawyer_matches = re.findall(r\"(?:Adv(?:ogado)?(?:\\(a\\))?|Procurador)\\W[^A-Z]*([A-Z][^\\n(-]*)\", content)\n",
    "    lawyers = []\n",
    "\n",
    "    for lawyer in lawyer_matches:\n",
    "        if lawyer and len(lawyer.split()) <= 5:\n",
    "            lawyers.append(lawyer.strip())\n",
    "        \n",
    "    return '/'.join(lawyers).lower() if lawyers else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tipo_financiamento(text):\n",
    "    tipo = {\n",
    "        ' consignado': re.compile('(^|\\W)consignado.*', re.IGNORECASE),\n",
    "        ' de veiculo': re.compile('((^|\\W)veiculo.*|(^|\\W)carro.*|(^|\\W)automove.*|(^|\\W)onibus.*|(^|\\W)moto\\W.*|(^|\\W)motocicleta.*)', re.IGNORECASE),\n",
    "    }\n",
    "    \n",
    "    for key in tipo:\n",
    "        if tipo[key].search(text) is not None:\n",
    "            return key\n",
    "    \n",
    "    return ''\n",
    "\n",
    "def get_produto(text):\n",
    "    text = normalized(text)\n",
    "    matches = []\n",
    "    regex_financiamento = '((^|\\W)d?[o,e,a]((^|\\W)financia\\w*.*|(^|\\W)emprest.*)|contrato de((^|\\W)financia\\w*.*|(^|\\W)emprest.*)|((^|\\W)financia\\w+|(^|\\W)emprestimo)\\Wcontratado)'\n",
    "    regex_cartao = '((^|\\W)credito.*(^|\\W)cartao.*|(^|\\W)cartao.*(^|\\W)credito.*)'\n",
    "    financiamento = re.compile(regex_financiamento, re.IGNORECASE)\n",
    "    cartao = re.compile(regex_cartao, re.IGNORECASE)\n",
    "    \n",
    "    if financiamento.search(text) is not None:\n",
    "        matches = ['financiamento'+tipo_financiamento(text)]\n",
    "    if cartao.search(text) is not None:\n",
    "        matches.append('cartao de credito')\n",
    "            \n",
    "    return '/'.join(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_argumento(sentences):\n",
    "    p = re.compile('(^|\\W)contest\\w+\\W|(^|\\W)aleg[a,o]\\w*\\W', re.IGNORECASE)\n",
    "    first = last = -1\n",
    "    for index, sentence in enumerate(sentences):\n",
    "        if p.search(sentence) is not None:\n",
    "            if first < 0:\n",
    "                first = index\n",
    "                last = index\n",
    "            else:\n",
    "                last = index\n",
    "    return first, last\n",
    "\n",
    "def filter_argumento(sentences):\n",
    "    p = re.compile('\\w*procede\\w*', re.IGNORECASE)\n",
    "    res = []\n",
    "    for sentence in sentences:\n",
    "        if p.search(sentence) is None:\n",
    "            sentence = sentence.strip().replace('\\n', ' ').replace('\\r', '')\n",
    "            res.append(sentence)\n",
    "    return res\n",
    "\n",
    "def get_argumento(text):\n",
    "    text = normalized(text)\n",
    "    sentences = text.split('.')\n",
    "    first, last = find_argumento(sentences)\n",
    "    if first >= 0:\n",
    "        res = sentences[first:last]\n",
    "        filtered = filter_argumento(res)\n",
    "        if len(filtered) > 0:\n",
    "            return '.'.join(filtered)\n",
    "        \n",
    "    sentences = filter_argumento(sentences)\n",
    "    \n",
    "    return '. '.join(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_target(text):\n",
    "    match = re.search(r'.{20}parcialmente.{20}', text, re.DOTALL | re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group()\n",
    "\n",
    "def get_target(text):\n",
    "    procedente_positions = [m.start() for m in re.finditer(' procedente', text, re.IGNORECASE)]\n",
    "    improcedente_positions = [m.start() for m in re.finditer('improcedente', text, re.IGNORECASE)]\n",
    "    if len(improcedente_positions) > 0 and len(procedente_positions) == 0: \n",
    "        return 1\n",
    "    \n",
    "    elif len(improcedente_positions) == 0 and len(procedente_positions) > 0: \n",
    "        return 0\n",
    "    \n",
    "    elif len(improcedente_positions) > 0 and len(procedente_positions) > 0:\n",
    "        return int(improcedente_positions[-1] > procedente_positions[-1])\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_motivo_frequency(text):\n",
    "    result_ind = re.findall(r'indenizacao|dano moral|negativacao|reparacao de danos|fraudulento|fraude|lucro cessante|dano material', text, re.DOTALL | re.IGNORECASE)\n",
    "    result_rev = re.findall(r'revisao|clausulas contratuais|comissao de permanencia|juros moratorios|encargos', text, re.DOTALL | re.IGNORECASE)\n",
    "    result_tarifa = re.findall(r'Repeticao de indebito|Tarifa de cadastro|Servicos de terceiros|Custo efetivo total|Tarifas', text, re.DOTALL | re.IGNORECASE)\n",
    "    return (len(result_ind), len(result_rev), len(result_tarifa))\n",
    "\n",
    "def get_motivo(text):\n",
    "    text = normalized(text)\n",
    "    ind, rev, tarifa = get_motivo_frequency(text)\n",
    "    if ind > rev and ind > tarifa:\n",
    "        return (ind, rev, tarifa, 'indenizacao')\n",
    "    if rev > ind and rev > tarifa:\n",
    "        return (ind, rev, tarifa, 'revisao')\n",
    "    if tarifa > rev and tarifa > ind:\n",
    "        return (ind, rev, tarifa, 'tarifa')\n",
    "    else:\n",
    "        return (ind, rev, tarifa, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = {\n",
    "    'codigo': [],\n",
    "    'nro': [],\n",
    "    'uf': [],\n",
    "    'comarca/cidade': [],\n",
    "    'vara': [],\n",
    "    'juiz': [],\n",
    "    'autor': [],\n",
    "    #'data': [],\n",
    "    'advogado': [],\n",
    "    'indenizacao_count': [],\n",
    "    'revisao_count': [],\n",
    "    'tarifa_count': [],\n",
    "    'motivo': [],\n",
    "    'produto': [],\n",
    "    'argumentos': [],\n",
    "    'target': [],\n",
    "}\n",
    "\n",
    "for text, filename in document_iterator(DIR):\n",
    "    result['codigo'].append(get_codigo(filename))\n",
    "    result['nro'].append(get_process_num(text))\n",
    "    uf, comarca = get_estado_e_comarca(text)\n",
    "    result['uf'].append(uf)\n",
    "    result['comarca/cidade'].append(comarca)\n",
    "    result['vara'].append(get_vara(text))\n",
    "    result['juiz'].append(get_juiz(text))\n",
    "    result['autor'].append(get_author(text))\n",
    "    #data\n",
    "    result['advogado'].append(get_lawyer(text))\n",
    "    indenizacao, revisao, tarifa, tipo = get_motivo(text)\n",
    "    result['indenizacao_count'].append(indenizacao)\n",
    "    result['revisao_count'].append(revisao)\n",
    "    result['tarifa_count'].append(tarifa)\n",
    "    result['motivo'].append(tipo)\n",
    "    result['produto'].append(get_produto(text))\n",
    "    result['argumentos'].append(get_argumento(text))\n",
    "    result['target'].append(get_target(text))\n",
    "\n",
    "pd.DataFrame(result).to_csv('sample_1000.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
