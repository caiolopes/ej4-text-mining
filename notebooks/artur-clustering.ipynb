{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob('../data/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file):\n",
    "    return open(file, 'r', encoding='cp1254').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_middle(text):\n",
    "    split = text.split('\\n')\n",
    "    N = len(split)\n",
    "    return \" \".join(split[N//4:N//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [get_middle(open_file(f)) for f in files[1:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "728"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "857"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_tokenize(data[0], language='portuguese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords = pd.read_csv('stopwords.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords = stopwords.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords = list(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CountVectorizer(encoding='cp1254', stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = encoder.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = encoder.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=20,n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/decomposition/online_lda.py:532: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
       "             learning_offset=10.0, max_doc_update_iter=100, max_iter=10,\n",
       "             mean_change_tol=0.001, n_components=20, n_jobs=4,\n",
       "             n_topics=None, perp_tol=0.1, random_state=None,\n",
       "             topic_word_prior=None, total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx), end=' ')\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.Text(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: p e r i o d i c...>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: adv catusso joseane 029 decidia 16190 render guimaraes 421b997c 10910502 0351 vasconcelos agudo bandeirantes wellington rmm1civel betim _________________ 3330988 01ec98af6d5eaadce44cf7a4d6cf6066 aasp pjvyq 4yl8m 16706 cw54a hvdbb 0001657 0002797 0374 julia\n",
      "\n",
      "\n",
      "Topic 1: de do que da em dano por se moral não no danos ao autora indenização morais ou na responsabilidade dos com os como consumidor para ser pela sua valor fato\n",
      "\n",
      "\n",
      "Topic 2: ros02vara 28890 camponar henriqueassumpcao js 0004133 0002158 66635 2vciv 3422 007018 3399 18093 nao pdf btn 0655 0003959 promoverá ganhasse autolimitação leviano estendesse 70046590535 aleatórias peremptórios outorgassem reverência banida 70018683722\n",
      "\n",
      "\n",
      "Topic 3: txh qmr ı0 mxurv domr grv frpr freudqod ÿ0 sru sdud frqwudwr ü9 4ı 17 vhu frp shor 025 vxd qrv frplvvmr 26 7ulexqdo shupdqrqfld ı9 ı3 fdslwdol frqvxplgru lqvwlwxlomr\n",
      "\n",
      "\n",
      "Topic 4: ÿå üå ÿé ÿç ÿî íå éı ÿí ìğ îı ñg ñk ìi çı ¼² ÿì bonita íÿ hî ûç 0538 µí ñµ îk ì8 wè 9ìé hñ dì gê\n",
      "\n",
      "\n",
      "Topic 5: projudi tjpr assinado digitalmente nº do 11 16 mov resolução sentença 200 validação deste oe 419 ref 2006 identificador arq https 2001 conforme julgada documento mp processo ação em procedente\n",
      "\n",
      "\n",
      "Topic 6: vw de ab rs 56 uv st cd bc tu wx 23 ut uw ge ev sv ba sr df 96 wv du ef dc ts 45 xy vx qr\n",
      "\n",
      "\n",
      "Topic 7: de do da que em juros não no se ao contrato cobrança com taxa por dos para as ou tarifa crédito os na capitalização ser pelo nº pela remuneratórios art\n",
      "\n",
      "\n",
      "Topic 8: de do que da em se não no ao com por para os parte na dos contrato as ação autor autora autos pelo ou pela art nos como direito pedido\n",
      "\n",
      "\n",
      "Topic 9: danna persiani carrilho catanduva 14255 0012292 9e17db4b48d1b7173ef26dc01c205bb3 1634580 jarbas 14121120275267500000000271012 0004368 0007877 44361 0009016 0302 0139 fctps 0082405 8dn96 pjspf hlxfr kc3mr pjt9g rmt6a 0029268 kumz5 cataneo macieo zetola 9938\n",
      "\n",
      "\n",
      "Topic 10: 53 82 73 34 80 63 78 ²ª 48 ²½ 43 93 32 98 87 ²¼ 25 79 46 36 23 zz 83 77 81 99 95 66 84 59\n",
      "\n",
      "\n",
      "Topic 11: de id co to in ra do re te da is ta se ia ro ju it em es en io as la ca ão no an pa os ap\n",
      "\n",
      "\n",
      "Topic 12: by scanned camscanner ituverava 0288 0006176 _bv_ pnl5g 6611 _so_tac_ pjy88 79_ _dr_mario g6quu _prescrição_ 0006611 _abusividade_ yyxyy _procedente_ _revisional_ 0xx lacer 4716 4civelresidual 69301 69666890682jarbas 0802695 amazônia pj6sp bf2ad\n",
      "\n",
      "\n",
      "Topic 13: de esaj 26 paulo br jus fls cep para original do comarca vara site por acesse informe estado este digitalmente assinado tjsp processo código documento se tribunal sp justiça rua\n",
      "\n",
      "\n",
      "Topic 14: de que não em se do consumidor da ou ao por os art dos das com as cdc contrato ser no para seu como na cláusulas um uma sua mais\n",
      "\n",
      "\n",
      "Topic 15: 0170 äº 0110 039 graca 15302 serra mococa olímpia leticia 0039 juizado manuel cívico 3313 79003 park thais 0400 0322 taboão 0159 0360 vargem tavares pirassununga rally 340 0044 ederson\n",
      "\n",
      "\n",
      "Topic 16: de 10 2015 2014 2013 juiz 05 09 12 para 08 11 02 04 2016 juntada 01 03 autos 07 06 despacho 2012 advogado vara 14 17 15 audiência 16\n",
      "\n",
      "\n",
      "Topic 17: impedem 164 alicerce 939242 phellipe 0309449 0164 andrea 3623 5710 0012732 dd2dc0785fe02ae7c40806acadd699f1 3659068 0001435 098 ilha 1079746 solteira 0002532 guariba müller conceituados 56962 0005037 0009893 13511 1110283 556eef7 bsz desembolsando\n",
      "\n",
      "\n",
      "Topic 18: ½ã åº ½ä ½ò ô¼ï òº 6851 ëh nz gî fâ áx ïv ö¼ ²h the uı ïh gğef emília 1í 1016138 äh 6850 6i6 òºî oficialidade pacaembu 48d111ff793465c5f69f43071a2af441 1657319\n",
      "\n",
      "\n",
      "Topic 19: gh fg èé äå qr úû îï àá hi ef ëì øù ip çè ğñ êë öï æç åæ if òï 6u ûü íî hf ğï rs éú ôõ wy\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_topics(lda, feature_names, 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
